{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52197759-12a6-4b77-9136-46fa6b65e1fe",
   "metadata": {},
   "source": [
    "# A simple chatbot agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672e980c-3aa3-4c5b-be86-fdd8d99ae070",
   "metadata": {},
   "source": [
    "## Prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9ff4e11-079c-4817-9bf7-642769b0e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../..')\n",
    "\n",
    "from autogen import ConversableAgent, register_function\n",
    "\n",
    "# from inswitch.llm.model import get_openai_model_config\n",
    "from inswitch.agent.basic import get_chat_agent, get_fixed_reply_agent\n",
    "from inswitch.util.message import second_last_msg\n",
    "\n",
    "from usecases.fill.filluc.mockupnerv.session import make_request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4410e2",
   "metadata": {},
   "source": [
    "## The simplified knowledge-providing agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ba94ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/mockup_single_machine_tripple.txt\", \"r\") as api_doc:\n",
    "    content = api_doc.read()\n",
    "\n",
    "knowledge_provider = get_fixed_reply_agent(\n",
    "    'knowledge_provider',\n",
    "    reply=content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dd3e852",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_maker_message = '''You are the decision maker.\n",
    "You get the user's intents, together with some knowledge about \n",
    "what machines, services, workloads, version etc., are avaliable in the system.\n",
    "Based on these, you decide which workloads, and their versions, should be deployed on which machine.\n",
    "Only reply with the deployment plan'''\n",
    "\n",
    "decision_maker = get_chat_agent(\n",
    "    \"decision_maker\",\n",
    "    system_message=decision_maker_message\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648d130c-3018-45e2-9087-9283eab064bd",
   "metadata": {},
   "source": [
    "## The simplied doc providing agent: no RAG in it - only manually selected text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9338485-9ca3-44b6-9540-e60d2f8782f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/nerve_api_dna.txt\", \"r\") as api_doc:\n",
    "    content = api_doc.read()\n",
    "\n",
    "api_doc_provider = get_fixed_reply_agent(\n",
    "    'api_doc_provider', \n",
    "    reply=content\n",
    ")\n",
    "\n",
    "moderator = get_fixed_reply_agent(\n",
    "    name=\"moderator\",\n",
    "    reply = \"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7095ad68",
   "metadata": {},
   "source": [
    "## Here are the API invocation agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fabb733e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following parameters of the function 'make_request' with default values are not annotated: 'files', 'workaround'.\n"
     ]
    }
   ],
   "source": [
    "nerv_tool_driver_system_message = '''You are a helpful assistent.\n",
    "You have access to a tool to call the Nerve DNA API to fulfil the user's intent.\n",
    "You will get from the context a document of the Nerve DNA API.\n",
    "Using the document, you will figure out how to call the API, i.e., using what endpoint and method.\n",
    "You will also need to generate the configuration file as the data of the api call, to fulfil the task assigned to you.\n",
    "'''\n",
    "\n",
    "nerv_tool_driver = get_chat_agent(\n",
    "    \"nerv_tool_driver\",\n",
    "    system_message = nerv_tool_driver_system_message\n",
    ")\n",
    "\n",
    "nerv_tool_executor = get_fixed_reply_agent(\n",
    "    \"nerv_tool_executor\",\n",
    "    reply = \"\"\n",
    ")\n",
    "\n",
    "register_function(\n",
    "    make_request,\n",
    "    caller = nerv_tool_driver,\n",
    "    executor = nerv_tool_executor,\n",
    "    description = \"This is the functionto send a request to the Nerve API for deploying workloads etc. \"\n",
    ")\n",
    "\n",
    "nerv_tool_executor.register_nested_chats(\n",
    "    [\n",
    "        {\n",
    "            \"recipient\": nerv_tool_driver,\n",
    "            \"max_turns\": 2,\n",
    "            \"summary_method\": second_last_msg\n",
    "        }\n",
    "    ],\n",
    "    trigger = lambda sender: sender not in [nerv_tool_driver]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900991d4-12d5-41d5-9d19-486ff5dd9386",
   "metadata": {},
   "source": [
    "## Here we go!\n",
    "A simple sequence: user_intent -> api_doc_provider -> nerv_tool_executor\n",
    "\n",
    "Current intent is hard coded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "042c02b5-36d3-4c6e-8526-51f4c102eb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mmoderator\u001b[0m (to intent_provier):\n",
      "\n",
      "what do you want?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mintent_provier\u001b[0m (to moderator):\n",
      "\n",
      "I am Customer1. \n",
      "I want to add a new service to my machine to record all the alarms\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mmoderator\u001b[0m (to knowledge_provider):\n",
      "\n",
      "What do you know about the system\n",
      "Context: \n",
      "I am Customer1. \n",
      "I want to add a new service to my machine to record all the alarms\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mknowledge_provider\u001b[0m (to moderator):\n",
      "\n",
      "Customer1 has_machine M00001\n",
      "M00001 has_type MTC\n",
      "\n",
      "ALARM_ANALYZER is Service\n",
      "ENERGY_TRACKER is Service\n",
      "\n",
      "ALARM_ANALYZER has_component Backend\n",
      "ALARM_ANALYZER has_component AlarmRecord\n",
      "ALARM_ANALYZER has_component Notifier\n",
      "\n",
      "ENERGY_TRACKER has_component Backend\n",
      "ENERGY_TRACKER has_component EnergyAnalysis\n",
      "\n",
      "Backend has_workload ngix\n",
      "Backend has_workload nodejs\n",
      "\n",
      "AlarmRecord has_workload alarm_record\n",
      "Notifier has_workload mqtt_sender\n",
      "\n",
      "EnergyAnalysis has_workload energy_collector\n",
      "EnergyAnalysis has_workload energy_aggregator\n",
      "\n",
      "ngix workload_version ngix_27\n",
      "ngix_27 version_number 1.27.2\n",
      "\n",
      "nodejs workload_version nodejs_23\n",
      "nodejs_23 version_number 23.2.0\n",
      "\n",
      "alarm_record workload_version alarm_record_1\n",
      "alarm_record_1 version_number 1.1\n",
      "\n",
      "alarm_record workload_version alarm_record_2\n",
      "alarm_record_2 version_number 1.2\n",
      "\n",
      "alarm_record workload_version alarm_record_3\n",
      "alarm_record_2 version_number 1.3\n",
      "\n",
      "mqtt_sender workload_version mqtt_sender_1\n",
      "mqtt_sender_1 version_number 1.21.1\n",
      "\n",
      "energy_aggregator workload_version energy_aggregator_1\n",
      "energy_aggregator_1 version_number 1.1\n",
      "\n",
      "energy_collector workload_version energy_collector_1\n",
      "energy_collector_1 version_number 1.1.1\n",
      "\n",
      "ngix_27 can_deploy_on MTC\n",
      "nodejs_23 can_deploy_on MTC\n",
      "alarm_record_2 can_deploy_on MTC\n",
      "mqtt_sender_1 can_deploy_on MTC\n",
      "energy_aggregator_1 can_deploy_on MTC\n",
      "energy_collector_1 can_deploy_on MTC\n",
      "\n",
      "\n",
      "ALARM_ANALYZER description \"records all alarms and messages and identifies the main messages. Actual machine problems can thus be identified.\"\n",
      "ENERGY_TRACKER description \"ENERGY TRACKER monitors media consumption and ensures early detection of production changes and leaks that might otherwise go undetected\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mmoderator\u001b[0m (to decision_maker):\n",
      "\n",
      "What should be deployed\n",
      "Context: \n",
      "I am Customer1. \n",
      "I want to add a new service to my machine to record all the alarms\n",
      "\n",
      "Customer1 has_machine M00001\n",
      "M00001 has_type MTC\n",
      "\n",
      "ALARM_ANALYZER is Service\n",
      "ENERGY_TRACKER is Service\n",
      "\n",
      "ALARM_ANALYZER has_component Backend\n",
      "ALARM_ANALYZER has_component AlarmRecord\n",
      "ALARM_ANALYZER has_component Notifier\n",
      "\n",
      "ENERGY_TRACKER has_component Backend\n",
      "ENERGY_TRACKER has_component EnergyAnalysis\n",
      "\n",
      "Backend has_workload ngix\n",
      "Backend has_workload nodejs\n",
      "\n",
      "AlarmRecord has_workload alarm_record\n",
      "Notifier has_workload mqtt_sender\n",
      "\n",
      "EnergyAnalysis has_workload energy_collector\n",
      "EnergyAnalysis has_workload energy_aggregator\n",
      "\n",
      "ngix workload_version ngix_27\n",
      "ngix_27 version_number 1.27.2\n",
      "\n",
      "nodejs workload_version nodejs_23\n",
      "nodejs_23 version_number 23.2.0\n",
      "\n",
      "alarm_record workload_version alarm_record_1\n",
      "alarm_record_1 version_number 1.1\n",
      "\n",
      "alarm_record workload_version alarm_record_2\n",
      "alarm_record_2 version_number 1.2\n",
      "\n",
      "alarm_record workload_version alarm_record_3\n",
      "alarm_record_2 version_number 1.3\n",
      "\n",
      "mqtt_sender workload_version mqtt_sender_1\n",
      "mqtt_sender_1 version_number 1.21.1\n",
      "\n",
      "energy_aggregator workload_version energy_aggregator_1\n",
      "energy_aggregator_1 version_number 1.1\n",
      "\n",
      "energy_collector workload_version energy_collector_1\n",
      "energy_collector_1 version_number 1.1.1\n",
      "\n",
      "ngix_27 can_deploy_on MTC\n",
      "nodejs_23 can_deploy_on MTC\n",
      "alarm_record_2 can_deploy_on MTC\n",
      "mqtt_sender_1 can_deploy_on MTC\n",
      "energy_aggregator_1 can_deploy_on MTC\n",
      "energy_collector_1 can_deploy_on MTC\n",
      "\n",
      "\n",
      "ALARM_ANALYZER description \"records all alarms and messages and identifies the main messages. Actual machine problems can thus be identified.\"\n",
      "ENERGY_TRACKER description \"ENERGY TRACKER monitors media consumption and ensures early detection of production changes and leaks that might otherwise go undetected\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mdecision_maker\u001b[0m (to moderator):\n",
      "\n",
      "Deployment Plan:\n",
      "\n",
      "- Machine: M00001 (Type: MTC)\n",
      "\n",
      "  - Service: ALARM_ANALYZER\n",
      "\n",
      "    - Component: Backend\n",
      "      - Workload: ngix, Version: ngix_27 (1.27.2)\n",
      "      - Workload: nodejs, Version: nodejs_23 (23.2.0)\n",
      "\n",
      "    - Component: AlarmRecord\n",
      "      - Workload: alarm_record, Version: alarm_record_2 (1.2)\n",
      "\n",
      "    - Component: Notifier\n",
      "      - Workload: mqtt_sender, Version: mqtt_sender_1 (1.21.1)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Deployment Plan:\n",
      "\n",
      "- Machine: M00001 (Type: MTC)\n",
      "\n",
      "  - Service: ALARM_ANALYZER\n",
      "\n",
      "    - Component: Backend\n",
      "      - Workload: ngix, Version: ngix_27 (1.27.2)\n",
      "      - Workload: nodejs, Version: nodejs_23 (23.2.0)\n",
      "\n",
      "    - Component: AlarmRecord\n",
      "      - Workload: alarm_record, Version: alarm_record_2 (1.2)\n",
      "\n",
      "    - Component: Notifier\n",
      "      - Workload: mqtt_sender, Version: mqtt_sender_1 (1.21.1)\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mmoderator\u001b[0m (to deployment_plan_announcer):\n",
      "\n",
      "What should be deployed? on which machine?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mdeployment_plan_announcer\u001b[0m (to moderator):\n",
      "\n",
      "Deployment Plan:\n",
      "\n",
      "- Machine: M00001 (Type: MTC)\n",
      "\n",
      "  - Service: ALARM_ANALYZER\n",
      "\n",
      "    - Component: Backend\n",
      "      - Workload: ngix, Version: ngix_27 (1.27.2)\n",
      "      - Workload: nodejs, Version: nodejs_23 (23.2.0)\n",
      "\n",
      "    - Component: AlarmRecord\n",
      "      - Workload: alarm_record, Version: alarm_record_2 (1.2)\n",
      "\n",
      "    - Component: Notifier\n",
      "      - Workload: mqtt_sender, Version: mqtt_sender_1 (1.21.1)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mmoderator\u001b[0m (to api_doc_provider):\n",
      "\n",
      "Please provide me the api doc\n",
      "Context: \n",
      "Deployment Plan:\n",
      "\n",
      "- Machine: M00001 (Type: MTC)\n",
      "\n",
      "  - Service: ALARM_ANALYZER\n",
      "\n",
      "    - Component: Backend\n",
      "      - Workload: ngix, Version: ngix_27 (1.27.2)\n",
      "      - Workload: nodejs, Version: nodejs_23 (23.2.0)\n",
      "\n",
      "    - Component: AlarmRecord\n",
      "      - Workload: alarm_record, Version: alarm_record_2 (1.2)\n",
      "\n",
      "    - Component: Notifier\n",
      "      - Workload: mqtt_sender, Version: mqtt_sender_1 (1.21.1)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mapi_doc_provider\u001b[0m (to moderator):\n",
      "\n",
      "Nerve DNA revolves around the deployment of workloads, note the behavior of existing workloads when additional workloads are deployed through Nerve DNA depending on the restartAllWLs parameter inside the API call PUT /nerve/dna/{serialNumber}/target\n",
      "\n",
      "The target configuration file is written in YAML format and applied to nodes through the PUT /nerve/dna/{serialNumber}/target call in the Management System API. Download the schema file here in order to validate the YAML file with a schema validator of choice.\n",
      "\n",
      "Here serialNumber is the unique id of the target machine.\n",
      "\n",
      "The target configuration YAML file can be uploaded by itself and does not need a specific file name.\n",
      "\n",
      "When declaring a workload in the target configuration, the name and version attributes are mandatory. While hash is not required, it is strongly recommended to ensure precise identification of the workload in some use cases. Refer to The importance of the hash below for more information.\n",
      "\n",
      "Take a look below for an example target configuration YAML file:\n",
      "\n",
      "schema_version: 1\n",
      "workloads:\n",
      "  - name: docker1\n",
      "    version: version-d1\n",
      "  - name: vm1\n",
      "    version: version-vm2\n",
      "    hash: hash4\n",
      "  - name: docker2\n",
      "    version: version-d2\n",
      "    hash: hash-d2\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mmoderator\u001b[0m (to nerv_tool_executor):\n",
      "\n",
      "you can see the intent and the knowledge in the context\n",
      "Context: \n",
      "Deployment Plan:\n",
      "\n",
      "- Machine: M00001 (Type: MTC)\n",
      "\n",
      "  - Service: ALARM_ANALYZER\n",
      "\n",
      "    - Component: Backend\n",
      "      - Workload: ngix, Version: ngix_27 (1.27.2)\n",
      "      - Workload: nodejs, Version: nodejs_23 (23.2.0)\n",
      "\n",
      "    - Component: AlarmRecord\n",
      "      - Workload: alarm_record, Version: alarm_record_2 (1.2)\n",
      "\n",
      "    - Component: Notifier\n",
      "      - Workload: mqtt_sender, Version: mqtt_sender_1 (1.21.1)\n",
      "Nerve DNA revolves around the deployment of workloads, note the behavior of existing workloads when additional workloads are deployed through Nerve DNA depending on the restartAllWLs parameter inside the API call PUT /nerve/dna/{serialNumber}/target\n",
      "\n",
      "The target configuration file is written in YAML format and applied to nodes through the PUT /nerve/dna/{serialNumber}/target call in the Management System API. Download the schema file here in order to validate the YAML file with a schema validator of choice.\n",
      "\n",
      "Here serialNumber is the unique id of the target machine.\n",
      "\n",
      "The target configuration YAML file can be uploaded by itself and does not need a specific file name.\n",
      "\n",
      "When declaring a workload in the target configuration, the name and version attributes are mandatory. While hash is not required, it is strongly recommended to ensure precise identification of the workload in some use cases. Refer to The importance of the hash below for more information.\n",
      "\n",
      "Take a look below for an example target configuration YAML file:\n",
      "\n",
      "schema_version: 1\n",
      "workloads:\n",
      "  - name: docker1\n",
      "    version: version-d1\n",
      "  - name: vm1\n",
      "    version: version-vm2\n",
      "    hash: hash4\n",
      "  - name: docker2\n",
      "    version: version-d2\n",
      "    hash: hash-d2\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mnerv_tool_executor\u001b[0m (to nerv_tool_driver):\n",
      "\n",
      "you can see the intent and the knowledge in the context\n",
      "Context: \n",
      "Deployment Plan:\n",
      "\n",
      "- Machine: M00001 (Type: MTC)\n",
      "\n",
      "  - Service: ALARM_ANALYZER\n",
      "\n",
      "    - Component: Backend\n",
      "      - Workload: ngix, Version: ngix_27 (1.27.2)\n",
      "      - Workload: nodejs, Version: nodejs_23 (23.2.0)\n",
      "\n",
      "    - Component: AlarmRecord\n",
      "      - Workload: alarm_record, Version: alarm_record_2 (1.2)\n",
      "\n",
      "    - Component: Notifier\n",
      "      - Workload: mqtt_sender, Version: mqtt_sender_1 (1.21.1)\n",
      "Nerve DNA revolves around the deployment of workloads, note the behavior of existing workloads when additional workloads are deployed through Nerve DNA depending on the restartAllWLs parameter inside the API call PUT /nerve/dna/{serialNumber}/target\n",
      "\n",
      "The target configuration file is written in YAML format and applied to nodes through the PUT /nerve/dna/{serialNumber}/target call in the Management System API. Download the schema file here in order to validate the YAML file with a schema validator of choice.\n",
      "\n",
      "Here serialNumber is the unique id of the target machine.\n",
      "\n",
      "The target configuration YAML file can be uploaded by itself and does not need a specific file name.\n",
      "\n",
      "When declaring a workload in the target configuration, the name and version attributes are mandatory. While hash is not required, it is strongly recommended to ensure precise identification of the workload in some use cases. Refer to The importance of the hash below for more information.\n",
      "\n",
      "Take a look below for an example target configuration YAML file:\n",
      "\n",
      "schema_version: 1\n",
      "workloads:\n",
      "  - name: docker1\n",
      "    version: version-d1\n",
      "  - name: vm1\n",
      "    version: version-vm2\n",
      "    hash: hash4\n",
      "  - name: docker2\n",
      "    version: version-d2\n",
      "    hash: hash-d2\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mnerv_tool_driver\u001b[0m (to nerv_tool_executor):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_ZuN45l6AentxDZJhm1SChc79): make_request *****\u001b[0m\n",
      "Arguments: \n",
      "{\"endpoint\":\"/nerve/dna/M00001/target\",\"method\":\"PUT\",\"data\":\"schema_version: 1\\nworkloads:\\n  - name: ngix\\n    version: ngix_27\\n  - name: nodejs\\n    version: nodejs_23\\n  - name: alarm_record\\n    version: alarm_record_2\\n  - name: mqtt_sender\\n    version: mqtt_sender_1\\n\"}\n",
      "\u001b[32m*****************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION make_request...\u001b[0m\n",
      "PUT: /nerve/dna/M00001/target:\n",
      "schema_version: 1\n",
      "workloads:\n",
      "  - name: ngix\n",
      "    version: ngix_27\n",
      "  - name: nodejs\n",
      "    version: nodejs_23\n",
      "  - name: alarm_record\n",
      "    version: alarm_record_2\n",
      "  - name: mqtt_sender\n",
      "    version: mqtt_sender_1\n",
      "\n",
      "\u001b[33mnerv_tool_executor\u001b[0m (to nerv_tool_driver):\n",
      "\n",
      "\u001b[33mnerv_tool_executor\u001b[0m (to nerv_tool_driver):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_ZuN45l6AentxDZJhm1SChc79) *****\u001b[0m\n",
      "done\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mnerv_tool_driver\u001b[0m (to nerv_tool_executor):\n",
      "\n",
      "The deployment plan has been executed successfully for Machine M00001. The specified workloads have been deployed according to your configuration.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mnerv_tool_executor\u001b[0m (to moderator):\n",
      "\n",
      "done\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user_intent = '''I am Customer1. \n",
    "I want to add a new service to my machine to record all the alarms\n",
    "'''\n",
    "\n",
    "intent_provider = get_fixed_reply_agent(\n",
    "    'intent_provier',\n",
    "    reply = user_intent\n",
    ")\n",
    "\n",
    "decision_chat_results = moderator.initiate_chats(\n",
    "    [\n",
    "        {\n",
    "            \"recipient\": intent_provider,\n",
    "            \"message\": \"what do you want?\",\n",
    "            \"max_turns\": 1,\n",
    "            \"summary_method\": \"last_msg\"\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": knowledge_provider,\n",
    "            \"message\": \"What do you know about the system\",\n",
    "            \"max_turns\": 1,\n",
    "            \"summary_method\": \"last_msg\"\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": decision_maker,\n",
    "            \"message\": \"What should be deployed\",\n",
    "            \"max_turns\": 1,\n",
    "            \"summary_method\": \"last_msg\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "deploy_plan = decision_chat_results[-1].summary\n",
    "\n",
    "print(deploy_plan)\n",
    "\n",
    "deployment_plan_announcer = get_fixed_reply_agent(\n",
    "    'deployment_plan_announcer',\n",
    "    reply=deploy_plan\n",
    ")\n",
    "\n",
    "chat_result = moderator.initiate_chats(\n",
    "    [\n",
    "        {\n",
    "            \"recipient\": deployment_plan_announcer,\n",
    "            \"message\": \"What should be deployed? on which machine?\",\n",
    "            \"max_turns\": 1,\n",
    "            \"summary_method\": \"last_msg\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": api_doc_provider,\n",
    "            \"message\": \"Please provide me the api doc\",\n",
    "            \"max_turns\": 1,\n",
    "            \"summary_method\": \"last_msg\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": nerv_tool_executor,\n",
    "            \"message\": \"you can see the intent and the knowledge in the context\",\n",
    "            \"max_turns\": 1,\n",
    "            \"summary_method\": \"last_msg\"\n",
    "        }\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e66e5f0",
   "metadata": {},
   "source": [
    "## Next steps:\n",
    "\n",
    "1. Replace current api_doc_provider (a fixed_reply_agent) by a RAG assistant, that extracts from a complete API document the parts that are relevant to DNA and deployment.\n",
    "2. Add in the beginning of the sequence another agent (or agents) to extract the list of workloads. Eventually, the input intent should be like \"I want to be able to monitor the thermal stability of machine M0001\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
